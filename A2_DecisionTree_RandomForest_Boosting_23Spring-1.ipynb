{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_81u4D3WhUu"
      },
      "source": [
        "# This jupyter notebook is prepared by “Your Full Name”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldYxL0f2k4An"
      },
      "source": [
        "# 1. Load Data and perform basic EDA (4pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1i4jxzBl2XK"
      },
      "source": [
        "### 1.1 import libraries: numpy, pandas, matplotlib.pyplot, seaborn, sklearn (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75PmFmzpR8yQ"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXc8-6YDmJsL"
      },
      "source": [
        "### 1.2 Upload the dataset to your Google Drive, then using the following code, import the data to a pandas dataframe and show the count of rows and columns (0.5pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdK1HFt5XOGR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "file_name = '/content/drive/MyDrive/Colab Notebooks/hr_data_.csv' #you may need to change this line depending on the location of your file in Google Drive\n",
        "with open(file_name, 'r') as file:\n",
        "    # TODO\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3KH9B2Gms7W"
      },
      "source": [
        "### 1.3 Show the top 7 and bottom 7 rows (0.5pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaEa4cRUmWip"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVdizy4enKsy"
      },
      "source": [
        "### 1.4 Show if any column has null values (0.5pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "youEZNzMnLbe"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z3XH127sPTk"
      },
      "source": [
        "### 1.5 Show/Plot the count of unique target labels and discuss its imbalances and possible issues in using it for classification. (1.5pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abZRsNaHrbij"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNbeIOjtynuO"
      },
      "source": [
        "# 2. Feature Selection and Pre-processing (25 pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owN9XnpJ1VWZ"
      },
      "source": [
        "## 2.1 Preprocessing City (1+1+1+1 = 4pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qDnMLJy1PPF"
      },
      "source": [
        "### 2.1.1 Plot no. of records per city so that the highest city counts are shown in descending order (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqC1hgu_sO--"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7WiOn891a7F"
      },
      "source": [
        "### 2.1.2 How many rows belong to the count-wise top 4 cities in total and how many for the remaining? (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL9nN1Im1DrD"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reZOuxsBSXGF"
      },
      "source": [
        "### 2.1.3 Replace the city name with city_others if the city name is not among the top 4 (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxrFi5k1Oirf"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J09Oz726Sv90"
      },
      "source": [
        "### 2.1.4 Show some sample data that the records have changed correctly. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esi0-ntwSvjX"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8Y0Fz4RTAHc"
      },
      "source": [
        "## 2.2. Preprocessing Education Level (1+2+2+1 = 6pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhNJLVAsTFT5"
      },
      "source": [
        "### 2.2.1. Show the unique values of education level. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIzfPOywTDEz"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbLeUaKvfttp"
      },
      "source": [
        "### 2.2.2. Write a function named replace_labels() that can replace labels using given {old_label:new_label} dictionary (2pts)\n",
        "\n",
        "Parameters: (1) dataframe, (2) a column name, (3) a dictionary with {old_label:new_label} mapping. \n",
        "\n",
        "Returns: a dataframe with specified column values replaced with the  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sptGBzaVfthA"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3RuKvE8iYBu"
      },
      "source": [
        "### 2.2.3. Using the replace_labels() function you just created, replace education_level column with ordinal values. The mapping can be like \"Graduate\":0, \"Masters\":1, \"Phd\":2 . (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW1ZzKCihO0L"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VibwcvMDnfHZ"
      },
      "source": [
        "### 2.2.4 Show some sample data that the records have changed appropriately (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkObFS_bnecp"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBI-qbDiXI2M"
      },
      "source": [
        "## 2.3. Preprocessing company_size (2+2+1 = 5pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP7UisA6ZS9X"
      },
      "source": [
        "### 2.3.1 Show the unique values of the company_size column and their counts (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYQ8sAQljncN"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1iq9fTcjWMU"
      },
      "source": [
        "### 2.3.2 Change the values of the company_size column from 0 to 7 where e0 is <10 and 7 is 10000+. The order of the numbers should be based on the values of the column-like an ordinary variable. (2pt)\n",
        "(Hint: you can use the replace_labels() function you created before.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi2Y6fJfeyDi"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1c8cj2wj0Bo"
      },
      "source": [
        "### 2.3.3 Show the updated unique values to validate they changed appropriately (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNWa09UxelPH"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ray9mgZGkMyg"
      },
      "source": [
        "## 2.4. Preprocessing last_new_job (1+2+1 = 4pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry0YEyP7kP51"
      },
      "source": [
        "### 2.4.1 Show unique values of the last_new_job column (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aGPR049kSuN"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KowRVFGOkXv4"
      },
      "source": [
        "### 2.4.2 Convert the values of this column to never->0, 1->1,....>4 -->5 (2pt)\n",
        "Hint: replace_labels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AfLULymkZu3"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T-Wjg6dk3Uj"
      },
      "source": [
        "### 2.4.3 Show the updated values (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpI9oBlbk5bb"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R2tk1uJlGa5"
      },
      "source": [
        "## 2.5 Preprocessing other columns (2pt total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuJyodTglKCH"
      },
      "source": [
        "### 2.5.1 Drop the enrollee_id, any unnamed columns, and any duplicate columns (if you created multiple columns one with original and one with updated, then remove the original one) (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8eJgpamlOfr"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDe7Tl50r4bW"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M9JeVgJowZm"
      },
      "source": [
        "## 2.6 Feature Scaling (3+1 = 4ps total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYeJBSu9o0-V"
      },
      "source": [
        "### 2.6.1 Use sklearn.preprocessing's MinMaxScaler to perform min max scaling to all the numeric columns (3pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TZHEB3srp2x"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vBopV2qo3zT"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCradyXLQWct"
      },
      "source": [
        "### 2.6.2 Show some of the scaled records. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUBUON0a1DqI"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAqPdBXbum0v"
      },
      "source": [
        "# 3. X/Y and Training/Test Split with stratified sampling (15pts in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0vy1uyKF5DV"
      },
      "source": [
        "### 3.1 Using a lot of features with categorical values is not memory-efficient. Use a LabelEncoder() to convert all the categorical columns to numeric labels. (This task is similar to previous assignment A1) (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTDOZN6adW3m"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgh6gbo__lAd"
      },
      "source": [
        "### 3.2 Copy all the features into X and the target to Y (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ5l0aLz_swD"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mxgOZ8bWCTG"
      },
      "source": [
        "### 3.3 Show the ratio of 1 and 0 in Y. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCTReI87WwIn"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYiNLcbZWw-p"
      },
      "source": [
        "### 3.4 Use sklearn's train_test_split() to split the data set into 70% training and 30% test sets. Set random_state to 42. We want to have the same ratio of 0 and 1 in the test set, use the stratify parameter to Y to ensure this. Then show the ratio of 1 and 0 in both train and test target. (4pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-h2q8R4XQxX"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9go74asN_4A3"
      },
      "source": [
        "### 3.5 Rebalancing (4+2 = 6pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcaOwlmnDFrN"
      },
      "source": [
        "3.5.1 Use imblearn's SMOTENC to balance the x_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMo87lbJSiIB"
      },
      "source": [
        "When our training set have class imbalance, we often perform over-sampling to generate synthetic data that can help in training. SMOTE is a library by imblearn for this purpose. The usage is fairly straightforward. See documentation [here](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) and a brief explanation with example [here](https://medium.com/analytics-vidhya/smote-nc-in-ml-categorization-models-fo-imbalanced-datasets-8adbdcf08c25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg5q3iNCaCX5"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOLWrq4EC6pN"
      },
      "source": [
        "3.5.2 Did that change the ratio in label? Confirm by printing the ratio in resampled labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX5UzM45CgKg"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEKsXRt-aDbT"
      },
      "source": [
        "# 4. Decision Tree (20pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW262Gdlakso"
      },
      "source": [
        "### 4.1 Initialize a decision tree model using sklearns DecisionTreeClassifier. Use the unbalanced training set. Set a consistent value for random_state parameter so that your result is reproducible. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ8TFB2kauD8"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl1qOJnvVXxh"
      },
      "source": [
        "### 4.2 Use grid search to find out the best combination of values for the parameters: criterion, max_depth, min_samples_split, max_features. Then print the best performing parameters. (4pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQpIAji7M_od"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJRSRsVeWC8y"
      },
      "source": [
        "### 4.3 Add the best performing parameter set to the already-initialized Decision Tree model. Then fit it on the train dataset. (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEaJbzrlQaBY"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPYRzwmIWeSZ"
      },
      "source": [
        "### 4.4 Import the accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score from scikitlearn's metrics package. Evaluate your Decision Tree on the Test dataset and print all the metrics. (3pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opr3pQspcwQN"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UP7aQs0GQwX"
      },
      "source": [
        "### 4.5 Plot the tree using scikitlearn's tree package. You may need to define a large figure size using matplotlib to have an intelligible figure. (2pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnwDm0uiE-KP"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmrdrwU-Dvf6"
      },
      "source": [
        "### 4.6 Initialize a new Decision Tree model, then use the best set of parameters from Step 4.3 to train it on the balanced train set that you prepared in Step 3.5.1. (3pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SD0orb7Dhdf"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICoCAMplYVKh"
      },
      "source": [
        "### 4.7 Print the evaluation scores (accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score) from the training on balanced dataset. (3pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VQUO4EvY0Xr"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMv-Nmaew3td"
      },
      "source": [
        "### 4.8 Discuss any difference between evaluation results from the unbalanced train set and balanced train set. (2pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c_ZSzbW1Opy"
      },
      "source": [
        "'#TODO'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x_h1QYuVSqQf"
      },
      "source": [
        "# 5. Random Forest Classifier (12pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36D52lOdVs2o"
      },
      "source": [
        "### 5.1 Use grid search to find best combinations of the following Random Forest parameters: n_estimators, max_depth, min_samples_split and min_samples_leaf. Use your own choice of scoring, criterion, number of folds for cross-validation for the model initialization. Remember the grid search can take a while to finish. (4pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogCCZd3XStni"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV2NO3hjaCEh"
      },
      "source": [
        "### 5.2 Print the best combination of parameters and use it to train a Random Forest classifier model. (3pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgzZUi_kWxyh"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p9ibWd8aSbk"
      },
      "source": [
        "### 5.3  Evaluate using the same metrics as before (accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score) (5pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d5bRGXyYa8Z"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XuX9sEUcu42"
      },
      "source": [
        "# 6. Boosting Classifier (20 pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9g6-WtWoQli"
      },
      "source": [
        "## 6.1 AdaBoost Classifier (10 pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94faLGF4dHDX"
      },
      "source": [
        "### 6.1.1 Perform a grid search for best values for parameters={n_estimators, learning_rate} of an AdaBoostClassifier and the given training set. (4pt) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFwyYsHQc0jb"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmofa6lXcG5l"
      },
      "source": [
        "### 6.1.2 Train an AdaboostClassifier using the best parameter set you found in step 6.1.1 (3pt) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiQmOcz8gjNi"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOpbWfoTcYMS"
      },
      "source": [
        "### 6.1.3 Evaluate using the same metrics as before (accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score) (3pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGS9o87aiQrP"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T2QO0aloZwg"
      },
      "source": [
        "## 6.2 Gradient Boosting Classifier (10 pts total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf-QJ-tVcnSU"
      },
      "source": [
        "### 6.2.1 Perform a grid search for best values for parameters={n_estimators, max_depth, learning_rate} of a GradientBoostingClassifier and the given training set. (4pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8erF7UBQhXd3"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRZKR-bHott5"
      },
      "source": [
        "### 6.2.2 Train a GradientBoostingClassifier using the best parameter set you found in step 6.2.1 (3pt) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAQZH-KqkrNq"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzVtBSlpo9wF"
      },
      "source": [
        "### 6.2.3 Evaluate using the same metrics as before (accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score) (3pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xl5Bdwyk8_W"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW4nKeUQ2Ewh"
      },
      "source": [
        "# 7. Summary Discussion (4 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSekQD9J2GTc"
      },
      "source": [
        "Which model yields the highest precision?\n",
        "\n",
        "Which model yields the lowest recall? \n",
        "\n",
        "Which model yields the higest True Positive (TP)? \n",
        "\n",
        "Which model yields the best performance overall? \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.3 (tags/v3.10.3:a342a49, Mar 16 2022, 13:07:40) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "60b64012b5ed67907a10276cfdedd88214213599e926916fcf8c83729d3a7c3a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
